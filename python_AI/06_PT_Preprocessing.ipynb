{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Preprocess-data\" data-toc-modified-id=\"Preprocess-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocess data</a></span></li><li><span><a href=\"#Split-data\" data-toc-modified-id=\"Split-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Split data</a></span></li><li><span><a href=\"#Tokenizer\" data-toc-modified-id=\"Tokenizer-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Tokenizer</a></span></li><li><span><a href=\"#LabelEncoder\" data-toc-modified-id=\"LabelEncoder-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>LabelEncoder</a></span></li><li><span><a href=\"#Padding\" data-toc-modified-id=\"Padding-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Padding</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTdCMVl9YAXw"
   },
   "source": [
    "# Preprocessing\n",
    "In this lesson, we will explore preprocessing and data loading utilities in Tensorflow + Keras, mainly focused on text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xuabAj4PYj57"
   },
   "source": [
    "<div align=\"left\">\n",
    "<a href=\"https://github.com/madewithml/lessons/blob/master/notebooks/02_Basics/06_Preprocessing/06_PT_Preprocessing.ipynb\" role=\"button\"><img class=\"notebook-badge-image\" src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
    "<a href=\"https://colab.research.google.com/github/madewithml/lessons/blob/master/notebooks/02_Basics/06_Preprocessing/06_PT_Preprocessing.ipynb\"><img class=\"notebook-badge-image\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtKqNioAayCy"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3OrtMpFayFC"
   },
   "source": [
    "We will download the [AG News dataset](http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html), which consists of 120000 text samples from 4 unique classes ('Business', 'Sci/Tech', 'Sports', 'World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NfIz_4OPYpG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vB2cOQXfsAD4"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "DATA_FILE = 'news.csv'\n",
    "INPUT_FEATURE = 'title'\n",
    "OUTPUT_FEATURE = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2368,
     "status": "error",
     "timestamp": 1583981040770,
     "user": {
      "displayName": "Goku Mohandas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjMIOf3R_zwS_zZx4ZyPMtQe0lOkGpPOEUEKWpM7g=s64",
      "userId": "00378334517810298963"
     },
     "user_tz": 420
    },
    "id": "zQjFjOsKsBJc",
    "outputId": "85991368-8bc1-436e-ae53-cf4723783f14"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b045c5f70805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPGNh-26V5gU"
   },
   "outputs": [],
   "source": [
    "# Load data from GitHub to this notebook's local drive\n",
    "url = \"https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv\"\n",
    "response = urllib.request.urlopen(url)\n",
    "html = response.read()\n",
    "with open(DATA_FILE, 'wb') as fp:\n",
    "    fp.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q14QCqKxUS2v"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(DATA_FILE, header=0)\n",
    "X = df[INPUT_FEATURE].values\n",
    "y = df[OUTPUT_FEATURE].values\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqQSfd6OjQR4"
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZPv7U5hjRnT"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Common text preprocessing steps.\"\"\"\n",
    "    # Remove unwanted characters\n",
    "    text = re.sub(r\"[^0-9a-zA-Z?.!,¿]+\", \" \", text)\n",
    "\n",
    "    # Add space between words and punctuations\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "\n",
    "    # Remove whitespaces\n",
    "    text = text.rstrip().strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRd0rgMojRqR"
   },
   "outputs": [],
   "source": [
    "# Preprocess the titles\n",
    "df.title = df.title.apply(preprocess_text)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ7adzmAEAFM"
   },
   "source": [
    "**NOTE**: If you have preprocessing steps like standardization, etc. that are calculated, you need to separate the training and test set first before spplying those operations. This is because we cannot apply any knowledge gained from the test set accidentally during preprocessing/training. However for preprocessing steps like the function above where we aren't learning anything from the data itself, we can perform before splitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0kEIDV2rWkPA"
   },
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNHCAonhWpQL"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXVnk18FsaiO"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSffHAoeQmBM"
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, val_size, test_size, shuffle):\n",
    "    \"\"\"Split data into train/val/test datasets.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, shuffle=shuffle)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_size, stratify=y_train, shuffle=shuffle)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEdM6iLjV_AY"
   },
   "outputs": [],
   "source": [
    "# Create data splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X, y=y, val_size=VAL_SIZE, test_size=TEST_SIZE, shuffle=SHUFFLE)\n",
    "class_counts = dict(collections.Counter(y))\n",
    "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")\n",
    "print (f\"Classes: {class_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh_Vox49XtlU"
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4_7i6x5rYcq"
   },
   "source": [
    "* **Tokenizer**: data processing unit to convert text data to tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JA359cgB4Lm"
   },
   "source": [
    "We could use something like Torch Text, SpaCy or Allen NLP, but the best tokenizer I've found so far is from Keras. In fact the entire preprocessing suite it worth checking out for text preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0EPk_ZGssHB"
   },
   "outputs": [],
   "source": [
    "# Use TensorFlow 2.x\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smMxvTPjthG8"
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBiqvYWJXvY1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoX-jiYwskMF"
   },
   "outputs": [],
   "source": [
    "LOWER = True\n",
    "CHAR_LEVEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsvjmXmIYVT5"
   },
   "outputs": [],
   "source": [
    "# Input vectorizer\n",
    "X_tokenizer = Tokenizer(lower=LOWER, char_level=CHAR_LEVEL, oov_token='<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aljdMgsdYlRl"
   },
   "outputs": [],
   "source": [
    "# Fit only on train data\n",
    "X_tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(X_tokenizer.word_index) + 1\n",
    "print (f\"# tokens: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5old1UfyY-EQ"
   },
   "outputs": [],
   "source": [
    "# Convert text to sequence of tokens\n",
    "print (f\"X_train[0]: {X_train[0]}\")\n",
    "X_train = np.array(X_tokenizer.texts_to_sequences(X_train))\n",
    "X_val = np.array(X_tokenizer.texts_to_sequences(X_val))\n",
    "X_test = np.array(X_tokenizer.texts_to_sequences(X_test))\n",
    "print (f\"X_train[0]: {X_train[0]}\")\n",
    "print (f\"len(X_train[0]): {len(X_train[0])} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3rTUi2jbN7e"
   },
   "source": [
    "**NOTE**: Checkout other preprocessing functions in the [official documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8P2N42lZKW2"
   },
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7Qw3ywlrcGp"
   },
   "source": [
    "* **LabelEncoder**: convert text labels to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bYN5NP1ZK0k"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrWsgug6ZGLs"
   },
   "outputs": [],
   "source": [
    "# Output vectorizer\n",
    "y_tokenizer = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7v4i94PZWgx"
   },
   "outputs": [],
   "source": [
    "# Fit on train data\n",
    "y_tokenizer = y_tokenizer.fit(y_train)\n",
    "classes = y_tokenizer.classes_\n",
    "print (f\"classes: {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8me9sECZZUL"
   },
   "outputs": [],
   "source": [
    "# Convert labels to tokens\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n",
    "y_train = y_tokenizer.transform(y_train)\n",
    "y_val = y_tokenizer.transform(y_val)\n",
    "y_test = y_tokenizer.transform(y_test)\n",
    "print (f\"y_train[0]: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3syfG98QSC1"
   },
   "outputs": [],
   "source": [
    "# Class weights\n",
    "counts = collections.Counter(y_train)\n",
    "class_weights = {_class: 1.0/count for _class, count in counts.items()}\n",
    "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuB6zUH_br7b"
   },
   "source": [
    "**NOTE**: Checkout the complete list of sklearn preprocessing functions in the [official documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96ZOlhGKp-ZG"
   },
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Fu2AmcJp-LC"
   },
   "source": [
    "Our inputs are all of varying length but we need each batch to be uniformly shaped. Therefore, we will use padding to make all the inputs in the batch the same length. Our padding index will be 0 (note that X_tokenizer starts at index 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHAxXfkvp99r"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tz2zOt67p9wK"
   },
   "outputs": [],
   "source": [
    "sample_X = np.array([[3, 89, 45]])\n",
    "max_seq_len = 10\n",
    "padded_sample_X = pad_sequences(sample_X, padding=\"post\", maxlen=max_seq_len)\n",
    "print (f\"{sample_X} → {padded_sample_X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTXqm5KMnyjJ"
   },
   "source": [
    "We'll be using in subsequent lessons on 2D and even 3D inputs and the same powerful `pad_sequences` function can be used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti6GqX_Nny4k"
   },
   "outputs": [],
   "source": [
    "# 2D inputs\n",
    "x = [[1, 2, 3], [1, 2, 3, 4]]\n",
    "max_seq_len = max([len(seq) for seq in x])\n",
    "x = pad_sequences(x, padding=\"post\", maxlen=max_seq_len)\n",
    "print (x)\n",
    "print (f\"shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVrpdj69ny8p"
   },
   "outputs": [],
   "source": [
    "# 3D inputs\n",
    "x = [ [[0, 1, 0], [1, 0, 0]],  [[1, 0, 0], [1, 0, 0], [0, 0, 1]]]\n",
    "max_seq_len = max([len(seq) for seq in x])\n",
    "x = pad_sequences(x, padding=\"post\", maxlen=max_seq_len)\n",
    "print (x)\n",
    "print (f\"shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKne710fcSZR"
   },
   "source": [
    "We will put all of these preprocessing utilities to use in the subsequent lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dh66tK82G2cL"
   },
   "source": [
    "---\n",
    "Share and discover ML projects at <a href=\"https://madewithml.com/\">Made With ML</a>.\n",
    "\n",
    "<div align=\"left\">\n",
    "<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://github.com/madewithml/lessons\"><img src=\"https://img.shields.io/github/stars/madewithml/lessons.svg?style=social&label=Star\"></a>&nbsp;\n",
    "<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://www.linkedin.com/company/madewithml\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n",
    "<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://twitter.com/madewithml\"><img src=\"https://img.shields.io/twitter/follow/madewithml.svg?label=Follow&style=social\"></a>\n",
    "</div>\n",
    "             "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "06_PT_Preprocessing",
   "provenance": [
    {
     "file_id": "https://github.com/madewithml/lessons/blob/master/notebooks/02_Basics/09_Preprocessing.ipynb",
     "timestamp": 1583210267430
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
